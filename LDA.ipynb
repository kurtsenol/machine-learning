{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "127XkgZN_lIDecaLzVB5Zdaey_b5X8fxB",
      "authorship_tag": "ABX9TyPuxPGzavTXNpYU2mOuoKiB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurtsenol/machine-learning/blob/master/LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDYD5nWf-XLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLTlRNqH9sQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = 'drive/My Drive/nipstxt/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx5XS7NW-A_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "06454209-3649-4ce0-a1ad-a3a4840d787e"
      },
      "source": [
        "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
        "folders"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nips00',\n",
              " 'nips01',\n",
              " 'nips02',\n",
              " 'nips03',\n",
              " 'nips04',\n",
              " 'nips05',\n",
              " 'nips06',\n",
              " 'nips07',\n",
              " 'nips08',\n",
              " 'nips09',\n",
              " 'nips10',\n",
              " 'nips11',\n",
              " 'nips12']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1rYfv9J-Lxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6579817-6926-4893-f572-1445530fafdc"
      },
      "source": [
        "# # Read all texts into a list.\n",
        "# papers = []\n",
        "\n",
        "# for folder in folders:\n",
        "#   file_names = os.listdir(DATA_PATH + folder)\n",
        "#   for file_name in file_names:\n",
        "#     with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
        "#       data = f.read()\n",
        "#     papers.append(data)\n",
        "# len(papers)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1740"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsL4XPcAzer2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pickle\n",
        "\n",
        "# with open(\"drive/My Drive/nipstxt/papers_pickle.txt\", \"wb\") as fp:   #Pickling\n",
        "#   pickle.dump(papers, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN-GOcVtzu3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"drive/My Drive/nipstxt/papers_pickle.txt\", \"rb\") as fp:   # Unpickling\n",
        "  papers = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdUIysxUK_2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9ee9140-e481-48ef-eea6-11ac4d54795c"
      },
      "source": [
        "len(papers)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1740"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vuItb4m-qX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "dea059f3-5779-4538-bb5b-877c6d1cb643"
      },
      "source": [
        "print(papers[0][:1000])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 \n",
            "CONNECTIVITY VERSUS ENTROPY \n",
            "Yaser S. Abu-Mostafa \n",
            "California Institute of Technology \n",
            "Pasadena, CA 91125 \n",
            "ABSTRACT \n",
            "How does the connectivity of a neural network (number of synapses per \n",
            "neuron) relate to the complexity of the problems it can handle (measured by \n",
            "the entropy)? Switching theory would suggest no relation at all, since all Boolean \n",
            "functions can be implemented using a circuit with very low connectivity (e.g., \n",
            "using two-input NAND gates). However, for a network that learns a problem \n",
            "from examples using a local learning rule, we prove that the entropy of the \n",
            "problem becomes a lower bound for the connectivity of the network. \n",
            "INTRODUCTION \n",
            "The most distinguishing feature of neural networks is their ability to spon- \n",
            "taneously learn the desired function from 'training' samples, i.e., their ability \n",
            "to program themselves. Clearly, a given neural network cannot just learn any \n",
            "function, there must be some restrictions on which networks can learn which \n",
            "functions. One obv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsKmLuZ8NJvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "be786a53-95c6-4925-9d9a-fc3fe1f836cd"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE4QUlAkNm-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "wnl = nltk.stem.wordnet.WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3Um26paNn2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_corpus(papers):\n",
        "  norm_papers = []\n",
        "  for paper in papers:\n",
        "    paper = paper.lower()\n",
        "    paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
        "    paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
        "    paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
        "    paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
        "    \n",
        "    paper_tokens = list(filter(None, paper_tokens))\n",
        "    if paper_tokens:\n",
        "      norm_papers.append(paper_tokens)\n",
        "  return norm_papers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIVKpYRzOxBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f4b1aa01-0c6c-4f9e-de64-620413fa567d"
      },
      "source": [
        "norm_papers = normalize_corpus(papers)\n",
        "print(len(norm_papers))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5nqymNlOxEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "51a86a19-02b4-42ec-f41a-eef162a7e75b"
      },
      "source": [
        "# viewing a processed paper\n",
        "print(norm_papers[0][:50])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['connectivity', 'versus', 'entropy', 'yaser', 'abu', 'mostafa', 'california', 'institute', 'technology', 'pasadena', 'ca', 'abstract', 'doe', 'connectivity', 'neural', 'network', 'number', 'synapsis', 'per', 'neuron', 'relate', 'complexity', 'problem', 'handle', 'measured', 'entropy', 'switching', 'theory', 'would', 'suggest', 'relation', 'since', 'boolean', 'function', 'implemented', 'using', 'circuit', 'low', 'connectivity', 'using', 'two', 'input', 'nand', 'gate', 'however', 'network', 'learns', 'problem', 'example', 'using']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOOpRS4A64X0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-SR-CMJ9ssN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram = gensim.models.Phrases(norm_papers, min_count=20, threshold=20, delimiter=b'_') # higher threshold fewer phrases.\n",
        "bigram_model = gensim.models.phrases.Phraser(bigram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSBEatXN9t-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5b4d403a-4dca-4a4c-8d8e-8d949167cc7b"
      },
      "source": [
        "# sample demonstration\n",
        "print(bigram_model[norm_papers[0]][:50])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['connectivity', 'versus', 'entropy', 'yaser', 'abu_mostafa', 'california_institute', 'technology_pasadena', 'ca_abstract', 'doe', 'connectivity', 'neural_network', 'number', 'synapsis', 'per', 'neuron', 'relate', 'complexity', 'problem', 'handle', 'measured', 'entropy', 'switching', 'theory', 'would', 'suggest', 'relation', 'since', 'boolean_function', 'implemented', 'using', 'circuit', 'low', 'connectivity', 'using', 'two', 'input', 'nand', 'gate', 'however', 'network', 'learns', 'problem', 'example', 'using', 'local', 'learning', 'rule', 'prove', 'entropy', 'problem']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZyY8BLQ-iRT",
        "colab_type": "text"
      },
      "source": [
        "Let’s generate phrases for all our tokenized research papers and build a vocabulary that will help us obtain a unique term/phrase to number mapping (since machine or deep learning only works on numeric tensors)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFh46xDM90kE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCx36Fhh-s7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "663032b6-311c-47ea-e450-08fe79a9e6e3"
      },
      "source": [
        "# Create a dictionary representation of the documents.\n",
        "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
        "\n",
        "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
        "print('Total Vocabulary Size:', len(dictionary))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample word to number mappings: [(0, '0a'), (1, '2h'), (2, '2h2'), (3, '2he'), (4, '2n'), (5, '__c'), (6, '_c'), (7, '_k'), (8, 'a2'), (9, 'ability'), (10, 'abu_mostafa'), (11, 'access'), (12, 'accommodate'), (13, 'according'), (14, 'accumulated')]\n",
            "Total Vocabulary Size: 78892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF7Rz39-_v-X",
        "colab_type": "text"
      },
      "source": [
        "Several of these terms are not very useful since they are specific to a paper or even a paragraph in a research paper. Hence, it is time to prune\n",
        "our vocabulary and start removing terms. Leveraging document frequency is a great way to achieve this. By now, you probably realize that the document frequency of a term is basically the total number of times that term occurs across all the documents in a corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc6PNXqH_0Kk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "204c4d8f-67f2-43dc-b471-724c8a8387f8"
      },
      "source": [
        "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
        "\n",
        "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
        "\n",
        "print('Total Vocabulary Size:', len(dictionary))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Vocabulary Size: 7756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWiJ9hBqAkra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "34fbfcbe-4062-4457-9cff-a6cb719b0584"
      },
      "source": [
        "print('Sample word to number mappings:', list(dictionary.items())[:15])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample word to number mappings: [(0, '2n'), (1, '_c'), (2, 'a2'), (3, 'ability'), (4, 'abu_mostafa'), (5, 'access'), (6, 'accommodate'), (7, 'according'), (8, 'accumulated'), (9, 'acknowledgement_work'), (10, 'addison_wesley'), (11, 'afosr'), (12, 'aip'), (13, 'air_force'), (14, 'although')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OcVpvc0APYn",
        "colab_type": "text"
      },
      "source": [
        "We removed all terms that occur fewer than 20 times across all documents and all\n",
        "terms that occur in more than 60% of all the documents. We are interested in finding different themes and topics and not recurring themes. Hence, this suits our scenario perfectly. We can now perform feature engineering by leveraging a simple Bag of Words model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U39C8CYI_0HJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f3f5903e-ea2d-4088-c6dc-c76332d16261"
      },
      "source": [
        "# Transforming corpus into bag of words vectors\n",
        "\n",
        "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
        "print(bow_corpus[1][:50])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(3, 2), (4, 1), (11, 1), (13, 1), (15, 1), (21, 1), (27, 1), (30, 1), (33, 1), (35, 2), (36, 1), (45, 1), (46, 1), (47, 1), (48, 2), (57, 2), (64, 7), (67, 4), (71, 3), (78, 1), (92, 3), (94, 2), (97, 9), (104, 1), (113, 1), (115, 4), (118, 4), (120, 2), (124, 4), (125, 3), (128, 1), (133, 5), (136, 3), (138, 1), (142, 3), (144, 6), (152, 2), (155, 1), (156, 1), (158, 1), (162, 1), (168, 1), (172, 1), (177, 12), (199, 1), (203, 14), (204, 1), (213, 1), (215, 1), (218, 4)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm5ZmUJo_0EA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "d97e9009-fa01-4985-da71-9a4e703542f0"
      },
      "source": [
        "# viewing actual terms and their counts\n",
        "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[1][:50]])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('ability', 2), ('abu_mostafa', 1), ('afosr', 1), ('air_force', 1), ('american_institute', 1), ('appendix', 1), ('assume', 1), ('asymptotic', 1), ('axe', 1), ('become', 2), ('becomes', 1), ('bt', 1), ('ca_abstract', 1), ('california_institute', 1), ('cannot', 2), ('complete', 2), ('connected', 7), ('consider', 4), ('corresponding', 3), ('denote', 1), ('ea', 3), ('ed', 2), ('element', 9), ('environment', 1), ('expected', 1), ('expression', 4), ('fact', 4), ('final', 2), ('fixed', 4), ('follows', 3), ('furthermore', 1), ('get', 5), ('go', 3), ('going', 1), ('hand', 3), ('hence', 6), ('implemented', 2), ('independent', 1), ('independently', 1), ('interested', 1), ('ity', 1), ('know', 1), ('le', 1), ('let', 12), ('need', 1), ('neuron', 14), ('next_section', 1), ('occur', 1), ('office_scientific', 1), ('otherwise', 4)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxKPqEe4_0A-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "113cd426-fc07-4c27-81fe-8c84e91bfd08"
      },
      "source": [
        "# total papers in the corpus\n",
        "\n",
        "print('Total number of papers:', len(bow_corpus))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of papers: 1740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZBkx5Z4LbKi",
        "colab_type": "text"
      },
      "source": [
        "### Latent Dirichlet Allocation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt1U3AzdMSF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TOTAL_TOPICS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o4Cs_rsBqam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, chunksize=1740, alpha='auto',\n",
        "                                   eta='auto', random_state=42, iterations=500, num_topics=TOTAL_TOPICS,\n",
        "                                   passes=20, eval_every=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szxcugE7MzUi",
        "colab_type": "text"
      },
      "source": [
        "Viewing the topics in our trained topic model is quite easy and we can generate them with the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlOqX5mcBrDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "bf82246b-8841-46c7-fa22-24f192ca4f66"
      },
      "source": [
        "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
        "  print('Topic #'+str(topic_id+1)+':')\n",
        "  print(topic)\n",
        "  print()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1:\n",
            "0.014*\"control\" + 0.008*\"unit\" + 0.007*\"state\" + 0.007*\"trajectory\" + 0.006*\"target\" + 0.006*\"dynamic\" + 0.006*\"movement\" + 0.006*\"motor\" + 0.005*\"position\" + 0.005*\"module\" + 0.005*\"task\" + 0.005*\"controller\" + 0.005*\"representation\" + 0.004*\"pattern\" + 0.004*\"change\" + 0.004*\"subject\" + 0.004*\"hand\" + 0.004*\"behavior\" + 0.004*\"arm\" + 0.003*\"activation\"\n",
            "\n",
            "Topic #2:\n",
            "0.012*\"chip\" + 0.011*\"circuit\" + 0.008*\"image\" + 0.007*\"current\" + 0.007*\"neuron\" + 0.006*\"voltage\" + 0.006*\"analog\" + 0.004*\"processor\" + 0.004*\"signal\" + 0.004*\"implementation\" + 0.004*\"bit\" + 0.004*\"design\" + 0.004*\"pixel\" + 0.004*\"line\" + 0.003*\"vector\" + 0.003*\"neural\" + 0.003*\"device\" + 0.003*\"digital\" + 0.003*\"application\" + 0.003*\"architecture\"\n",
            "\n",
            "Topic #3:\n",
            "0.027*\"state\" + 0.014*\"action\" + 0.009*\"policy\" + 0.008*\"control\" + 0.007*\"step\" + 0.007*\"reinforcement_learning\" + 0.006*\"optimal\" + 0.005*\"task\" + 0.005*\"environment\" + 0.004*\"reward\" + 0.004*\"goal\" + 0.004*\"agent\" + 0.004*\"td\" + 0.004*\"cost\" + 0.004*\"robot\" + 0.003*\"path\" + 0.003*\"controller\" + 0.003*\"current\" + 0.003*\"probability\" + 0.003*\"solution\"\n",
            "\n",
            "Topic #4:\n",
            "0.023*\"image\" + 0.012*\"object\" + 0.012*\"unit\" + 0.011*\"feature\" + 0.008*\"map\" + 0.008*\"visual\" + 0.007*\"layer\" + 0.006*\"region\" + 0.005*\"local\" + 0.005*\"representation\" + 0.004*\"view\" + 0.004*\"pattern\" + 0.004*\"position\" + 0.004*\"motion\" + 0.004*\"structure\" + 0.004*\"orientation\" + 0.004*\"location\" + 0.004*\"receptive_field\" + 0.004*\"pixel\" + 0.004*\"direction\"\n",
            "\n",
            "Topic #5:\n",
            "0.009*\"distribution\" + 0.007*\"probability\" + 0.006*\"vector\" + 0.005*\"matrix\" + 0.005*\"approximation\" + 0.005*\"class\" + 0.004*\"variable\" + 0.004*\"estimate\" + 0.004*\"density\" + 0.004*\"sample\" + 0.004*\"linear\" + 0.004*\"gaussian\" + 0.003*\"equation\" + 0.003*\"component\" + 0.003*\"let\" + 0.003*\"solution\" + 0.003*\"bound\" + 0.003*\"theory\" + 0.003*\"optimal\" + 0.003*\"xi\"\n",
            "\n",
            "Topic #6:\n",
            "0.012*\"state\" + 0.011*\"training\" + 0.010*\"speech\" + 0.009*\"word\" + 0.008*\"hmm\" + 0.007*\"signal\" + 0.007*\"recognition\" + 0.007*\"sequence\" + 0.006*\"mlp\" + 0.005*\"frame\" + 0.005*\"speaker\" + 0.005*\"context\" + 0.005*\"probability\" + 0.005*\"feature\" + 0.004*\"vector\" + 0.004*\"trained\" + 0.004*\"speech_recognition\" + 0.004*\"nonlinear\" + 0.004*\"prediction\" + 0.004*\"acoustic\"\n",
            "\n",
            "Topic #7:\n",
            "0.009*\"state\" + 0.008*\"vector\" + 0.008*\"unit\" + 0.007*\"node\" + 0.007*\"neuron\" + 0.005*\"memory\" + 0.005*\"dynamic\" + 0.005*\"pattern\" + 0.005*\"matrix\" + 0.005*\"equation\" + 0.004*\"net\" + 0.004*\"sequence\" + 0.004*\"layer\" + 0.004*\"threshold\" + 0.004*\"activation\" + 0.004*\"linear\" + 0.004*\"size\" + 0.004*\"let\" + 0.003*\"recurrent\" + 0.003*\"rule\"\n",
            "\n",
            "Topic #8:\n",
            "0.020*\"neuron\" + 0.017*\"cell\" + 0.010*\"response\" + 0.008*\"stimulus\" + 0.007*\"activity\" + 0.007*\"signal\" + 0.006*\"spike\" + 0.006*\"pattern\" + 0.005*\"synaptic\" + 0.005*\"frequency\" + 0.005*\"neural\" + 0.004*\"effect\" + 0.004*\"firing\" + 0.004*\"cortical\" + 0.004*\"noise\" + 0.004*\"connection\" + 0.003*\"et_al\" + 0.003*\"temporal\" + 0.003*\"change\" + 0.003*\"current\"\n",
            "\n",
            "Topic #9:\n",
            "0.015*\"training\" + 0.011*\"unit\" + 0.009*\"pattern\" + 0.008*\"classifier\" + 0.008*\"task\" + 0.006*\"feature\" + 0.006*\"classification\" + 0.006*\"hidden_unit\" + 0.006*\"trained\" + 0.006*\"class\" + 0.006*\"rule\" + 0.005*\"layer\" + 0.005*\"training_set\" + 0.004*\"architecture\" + 0.004*\"net\" + 0.004*\"recognition\" + 0.004*\"node\" + 0.004*\"representation\" + 0.004*\"word\" + 0.004*\"character\"\n",
            "\n",
            "Topic #10:\n",
            "0.009*\"training\" + 0.005*\"prediction\" + 0.005*\"distribution\" + 0.005*\"variable\" + 0.004*\"noise\" + 0.004*\"prior\" + 0.004*\"estimate\" + 0.004*\"test\" + 0.004*\"regression\" + 0.004*\"kernel\" + 0.004*\"linear\" + 0.003*\"class\" + 0.003*\"sample\" + 0.003*\"training_set\" + 0.003*\"vector\" + 0.003*\"bayesian\" + 0.003*\"tree\" + 0.003*\"step\" + 0.003*\"approximation\" + 0.003*\"gaussian\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLGppCR0NnUj",
        "colab_type": "text"
      },
      "source": [
        "all the weights are the same sign and tell us the importance of each term in the topic. We can also view the overall mean coherence score of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6Wy4GvYBqX8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f19eb3ab-e49f-44bd-9a50-682affb1850e"
      },
      "source": [
        "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)\n",
        "\n",
        "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
        "\n",
        "print('Avg. Coherence Score:', avg_coherence_score)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg. Coherence Score: -1.0190235012946323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb3YbZz4Oq1M",
        "colab_type": "text"
      },
      "source": [
        "Let’s now look at the output of our LDA topic model in an easier to understand format. One way is to visualize the topics as tuples of terms and weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0KhMSKLBqRy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "b1fe9bba-609e-471a-d347-4e01e2db5054"
      },
      "source": [
        "topics_with_wts = [item[0] for item in topics_coherences]\n",
        "\n",
        "print('LDA Topics with Weights')\n",
        "print('='*50)\n",
        "\n",
        "for idx, topic in enumerate(topics_with_wts):\n",
        "  print('Topic #'+str(idx+1)+':')\n",
        "  print([(term, round(wt, 3)) for wt, term in topic])\n",
        "  print()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LDA Topics with Weights\n",
            "==================================================\n",
            "Topic #1:\n",
            "[('neuron', 0.02), ('cell', 0.017), ('response', 0.01), ('stimulus', 0.008), ('activity', 0.007), ('signal', 0.007), ('spike', 0.006), ('pattern', 0.006), ('synaptic', 0.005), ('frequency', 0.005), ('neural', 0.005), ('effect', 0.004), ('firing', 0.004), ('cortical', 0.004), ('noise', 0.004), ('connection', 0.004), ('et_al', 0.003), ('temporal', 0.003), ('change', 0.003), ('current', 0.003)]\n",
            "\n",
            "Topic #2:\n",
            "[('distribution', 0.009), ('probability', 0.007), ('vector', 0.006), ('matrix', 0.005), ('approximation', 0.005), ('class', 0.005), ('variable', 0.004), ('estimate', 0.004), ('density', 0.004), ('sample', 0.004), ('linear', 0.004), ('gaussian', 0.004), ('equation', 0.003), ('component', 0.003), ('let', 0.003), ('solution', 0.003), ('bound', 0.003), ('theory', 0.003), ('optimal', 0.003), ('xi', 0.003)]\n",
            "\n",
            "Topic #3:\n",
            "[('state', 0.009), ('vector', 0.008), ('unit', 0.008), ('node', 0.007), ('neuron', 0.007), ('memory', 0.005), ('dynamic', 0.005), ('pattern', 0.005), ('matrix', 0.005), ('equation', 0.005), ('net', 0.004), ('sequence', 0.004), ('layer', 0.004), ('threshold', 0.004), ('activation', 0.004), ('linear', 0.004), ('size', 0.004), ('let', 0.004), ('recurrent', 0.003), ('rule', 0.003)]\n",
            "\n",
            "Topic #4:\n",
            "[('chip', 0.012), ('circuit', 0.011), ('image', 0.008), ('current', 0.007), ('neuron', 0.007), ('voltage', 0.006), ('analog', 0.006), ('processor', 0.004), ('signal', 0.004), ('implementation', 0.004), ('bit', 0.004), ('design', 0.004), ('pixel', 0.004), ('line', 0.004), ('vector', 0.003), ('neural', 0.003), ('device', 0.003), ('digital', 0.003), ('application', 0.003), ('architecture', 0.003)]\n",
            "\n",
            "Topic #5:\n",
            "[('training', 0.009), ('prediction', 0.005), ('distribution', 0.005), ('variable', 0.005), ('noise', 0.004), ('prior', 0.004), ('estimate', 0.004), ('test', 0.004), ('regression', 0.004), ('kernel', 0.004), ('linear', 0.004), ('class', 0.003), ('sample', 0.003), ('training_set', 0.003), ('vector', 0.003), ('bayesian', 0.003), ('tree', 0.003), ('step', 0.003), ('approximation', 0.003), ('gaussian', 0.003)]\n",
            "\n",
            "Topic #6:\n",
            "[('training', 0.015), ('unit', 0.011), ('pattern', 0.009), ('classifier', 0.008), ('task', 0.008), ('feature', 0.006), ('classification', 0.006), ('hidden_unit', 0.006), ('trained', 0.006), ('class', 0.006), ('rule', 0.006), ('layer', 0.005), ('training_set', 0.005), ('architecture', 0.004), ('net', 0.004), ('recognition', 0.004), ('node', 0.004), ('representation', 0.004), ('word', 0.004), ('character', 0.004)]\n",
            "\n",
            "Topic #7:\n",
            "[('image', 0.023), ('object', 0.012), ('unit', 0.012), ('feature', 0.011), ('map', 0.008), ('visual', 0.008), ('layer', 0.007), ('region', 0.006), ('local', 0.005), ('representation', 0.005), ('view', 0.004), ('pattern', 0.004), ('position', 0.004), ('motion', 0.004), ('structure', 0.004), ('orientation', 0.004), ('location', 0.004), ('receptive_field', 0.004), ('pixel', 0.004), ('direction', 0.004)]\n",
            "\n",
            "Topic #8:\n",
            "[('state', 0.027), ('action', 0.014), ('policy', 0.009), ('control', 0.008), ('step', 0.007), ('reinforcement_learning', 0.007), ('optimal', 0.006), ('task', 0.005), ('environment', 0.005), ('reward', 0.004), ('goal', 0.004), ('agent', 0.004), ('td', 0.004), ('cost', 0.004), ('robot', 0.004), ('path', 0.003), ('controller', 0.003), ('current', 0.003), ('probability', 0.003), ('solution', 0.003)]\n",
            "\n",
            "Topic #9:\n",
            "[('state', 0.012), ('training', 0.011), ('speech', 0.01), ('word', 0.009), ('hmm', 0.008), ('signal', 0.007), ('recognition', 0.007), ('sequence', 0.007), ('mlp', 0.006), ('frame', 0.005), ('speaker', 0.005), ('context', 0.005), ('probability', 0.005), ('feature', 0.005), ('vector', 0.004), ('trained', 0.004), ('speech_recognition', 0.004), ('nonlinear', 0.004), ('prediction', 0.004), ('acoustic', 0.004)]\n",
            "\n",
            "Topic #10:\n",
            "[('control', 0.014), ('unit', 0.008), ('state', 0.007), ('trajectory', 0.007), ('target', 0.006), ('dynamic', 0.006), ('movement', 0.006), ('motor', 0.006), ('position', 0.005), ('module', 0.005), ('task', 0.005), ('controller', 0.005), ('representation', 0.005), ('pattern', 0.004), ('change', 0.004), ('subject', 0.004), ('hand', 0.004), ('behavior', 0.004), ('arm', 0.004), ('activation', 0.003)]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QosWZ1K7QdYo",
        "colab_type": "text"
      },
      "source": [
        "We can also view the topics as a list of terms without the weights when we want to understand the context or theme conveyed by each topic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1jGXjmVBqPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "a4142be1-1883-48ae-865a-ce4382a74b9d"
      },
      "source": [
        "print('LDA Topics without Weights')\n",
        "print('='*50)\n",
        "\n",
        "for idx, topic in enumerate(topics_with_wts):\n",
        "  print('Topic #'+str(idx+1)+':')\n",
        "  print([term for wt, term in topic])\n",
        "  print()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LDA Topics without Weights\n",
            "==================================================\n",
            "Topic #1:\n",
            "['neuron', 'cell', 'response', 'stimulus', 'activity', 'signal', 'spike', 'pattern', 'synaptic', 'frequency', 'neural', 'effect', 'firing', 'cortical', 'noise', 'connection', 'et_al', 'temporal', 'change', 'current']\n",
            "\n",
            "Topic #2:\n",
            "['distribution', 'probability', 'vector', 'matrix', 'approximation', 'class', 'variable', 'estimate', 'density', 'sample', 'linear', 'gaussian', 'equation', 'component', 'let', 'solution', 'bound', 'theory', 'optimal', 'xi']\n",
            "\n",
            "Topic #3:\n",
            "['state', 'vector', 'unit', 'node', 'neuron', 'memory', 'dynamic', 'pattern', 'matrix', 'equation', 'net', 'sequence', 'layer', 'threshold', 'activation', 'linear', 'size', 'let', 'recurrent', 'rule']\n",
            "\n",
            "Topic #4:\n",
            "['chip', 'circuit', 'image', 'current', 'neuron', 'voltage', 'analog', 'processor', 'signal', 'implementation', 'bit', 'design', 'pixel', 'line', 'vector', 'neural', 'device', 'digital', 'application', 'architecture']\n",
            "\n",
            "Topic #5:\n",
            "['training', 'prediction', 'distribution', 'variable', 'noise', 'prior', 'estimate', 'test', 'regression', 'kernel', 'linear', 'class', 'sample', 'training_set', 'vector', 'bayesian', 'tree', 'step', 'approximation', 'gaussian']\n",
            "\n",
            "Topic #6:\n",
            "['training', 'unit', 'pattern', 'classifier', 'task', 'feature', 'classification', 'hidden_unit', 'trained', 'class', 'rule', 'layer', 'training_set', 'architecture', 'net', 'recognition', 'node', 'representation', 'word', 'character']\n",
            "\n",
            "Topic #7:\n",
            "['image', 'object', 'unit', 'feature', 'map', 'visual', 'layer', 'region', 'local', 'representation', 'view', 'pattern', 'position', 'motion', 'structure', 'orientation', 'location', 'receptive_field', 'pixel', 'direction']\n",
            "\n",
            "Topic #8:\n",
            "['state', 'action', 'policy', 'control', 'step', 'reinforcement_learning', 'optimal', 'task', 'environment', 'reward', 'goal', 'agent', 'td', 'cost', 'robot', 'path', 'controller', 'current', 'probability', 'solution']\n",
            "\n",
            "Topic #9:\n",
            "['state', 'training', 'speech', 'word', 'hmm', 'signal', 'recognition', 'sequence', 'mlp', 'frame', 'speaker', 'context', 'probability', 'feature', 'vector', 'trained', 'speech_recognition', 'nonlinear', 'prediction', 'acoustic']\n",
            "\n",
            "Topic #10:\n",
            "['control', 'unit', 'state', 'trajectory', 'target', 'dynamic', 'movement', 'motor', 'position', 'module', 'task', 'controller', 'representation', 'pattern', 'change', 'subject', 'hand', 'behavior', 'arm', 'activation']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqn7MvpyRWWK",
        "colab_type": "text"
      },
      "source": [
        "We can use perplexity and coherence scores as measures to evaluate the topic\n",
        "model. Typically, lower the perplexity, the better the model. Similarly, the lower the UMass score and the higher the Cv score in coherence, the better the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF7RZZ_k_z4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_coherence_model_lda = gensim.models.CoherenceModel( model=lda_model, corpus=bow_corpus, texts=norm_corpus_bigrams,\n",
        "                                                      dictionary=dictionary, coherence='c_v')\n",
        "\n",
        "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
        "\n",
        "umass_coherence_model_lda = gensim.models.CoherenceModel( model=lda_model, corpus=bow_corpus, texts=norm_corpus_bigrams,\n",
        "                                                          dictionary=dictionary, coherence='u_mass')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0X9vARjRVbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "500e45f8-3c81-40b1-9cc8-2dc97ebbac6d"
      },
      "source": [
        "\n",
        "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
        "perplexity = lda_model.log_perplexity(bow_corpus)\n",
        "\n",
        "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
        "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
        "print('Model Perplexity:', perplexity)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg. Coherence Score (Cv): 0.4952768212161648\n",
            "Avg. Coherence Score (UMass): -1.019023501294632\n",
            "Model Perplexity: -7.786467030429068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ThWeo4SUH6k",
        "colab_type": "text"
      },
      "source": [
        "### LDA Models with MALLET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5orXYqxNUDp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "807ecf33-d60e-4243-a987-9327f3e5ef58"
      },
      "source": [
        "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-22 21:37:12--  http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
            "Resolving mallet.cs.umass.edu (mallet.cs.umass.edu)... 128.119.246.70\n",
            "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16184794 (15M) [application/zip]\n",
            "Saving to: ‘mallet-2.0.8.zip’\n",
            "\n",
            "mallet-2.0.8.zip    100%[===================>]  15.43M  11.0MB/s    in 1.4s    \n",
            "\n",
            "2020-05-22 21:37:14 (11.0 MB/s) - ‘mallet-2.0.8.zip’ saved [16184794/16184794]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0q8wamCVmpp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c79cb281-4421-4860-9c2e-d318b63d03b9"
      },
      "source": [
        "!unzip mallet-2.0.8.zip"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  mallet-2.0.8.zip\n",
            "replace mallet-2.0.8/bin/classifier2info? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmGslcdMUCVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MALLET_PATH = '/content/mallet-2.0.8/bin/mallet'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cOLbgkuVahb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "932c0455-246d-4527-8fe2-0805f7129fd7"
      },
      "source": [
        "lda_mallet = gensim.models.wrappers.LdaMallet( mallet_path=MALLET_PATH, corpus=bow_corpus,\n",
        "                                              num_topics=TOTAL_TOPICS, id2word=dictionary,\n",
        "                                               iterations=500, workers=16)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBej7zBjZ6-L",
        "colab_type": "text"
      },
      "source": [
        "We can now look at the generated topics by leveraging the following code snippet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z5ZkyhKVbSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topics = [[(term, round(wt, 3)) for term, wt in lda_mallet.show_topic(n, topn=20)] for n in range(0, TOTAL_TOPICS)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkmjXutOaMIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "ccea66ac-2445-400b-fe5c-cdd1f5e00a1b"
      },
      "source": [
        "for idx, topic in enumerate(topics):\n",
        "  print('Topic #'+str(idx+1)+':')\n",
        "  print([term for term, wt in topic])\n",
        "  print()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1:\n",
            "['circuit', 'signal', 'current', 'chip', 'analog', 'bit', 'voltage', 'channel', 'implementation', 'source', 'design', 'neural', 'noise', 'processor', 'computation', 'memory', 'code', 'parallel', 'operation', 'application']\n",
            "\n",
            "Topic #2:\n",
            "['class', 'training', 'word', 'classification', 'classifier', 'recognition', 'feature', 'pattern', 'speech', 'trained', 'sequence', 'character', 'context', 'experiment', 'hmm', 'vector', 'probability', 'test', 'frame', 'mlp']\n",
            "\n",
            "Topic #3:\n",
            "['distribution', 'gaussian', 'variable', 'probability', 'estimate', 'matrix', 'prior', 'equation', 'component', 'density', 'vector', 'noise', 'mixture', 'approximation', 'variance', 'estimation', 'bayesian', 'eq', 'sample', 'log']\n",
            "\n",
            "Topic #4:\n",
            "['image', 'feature', 'object', 'representation', 'region', 'pixel', 'local', 'distance', 'cluster', 'view', 'face', 'surface', 'structure', 'location', 'clustering', 'vector', 'map', 'shape', 'transformation', 'position']\n",
            "\n",
            "Topic #5:\n",
            "['unit', 'layer', 'node', 'pattern', 'rule', 'net', 'hidden_unit', 'activation', 'architecture', 'representation', 'structure', 'training', 'connection', 'recurrent', 'task', 'sequence', 'back_propagation', 'vector', 'connectionist', 'hidden_layer']\n",
            "\n",
            "Topic #6:\n",
            "['state', 'control', 'action', 'step', 'trajectory', 'dynamic', 'task', 'policy', 'environment', 'controller', 'optimal', 'reinforcement_learning', 'path', 'goal', 'robot', 'transition', 'change', 'move', 'adaptive', 'initial']\n",
            "\n",
            "Topic #7:\n",
            "['neuron', 'dynamic', 'pattern', 'synaptic', 'spike', 'activity', 'connection', 'neural', 'firing', 'noise', 'rate', 'phase', 'synapsis', 'simulation', 'memory', 'fig', 'cell', 'state', 'effect', 'delay']\n",
            "\n",
            "Topic #8:\n",
            "['cell', 'response', 'stimulus', 'visual', 'motion', 'activity', 'receptive_field', 'direction', 'signal', 'unit', 'spatial', 'map', 'layer', 'target', 'eye', 'cortical', 'orientation', 'subject', 'field', 'velocity']\n",
            "\n",
            "Topic #9:\n",
            "['training', 'prediction', 'test', 'training_set', 'experiment', 'average', 'expert', 'task', 'generalization', 'measure', 'sample', 'selection', 'tree', 'technique', 'table', 'trained', 'regression', 'target', 'procedure', 'noise']\n",
            "\n",
            "Topic #10:\n",
            "['vector', 'class', 'linear', 'bound', 'convergence', 'theorem', 'size', 'solution', 'approximation', 'defined', 'theory', 'probability', 'xi', 'matrix', 'condition', 'constant', 'optimal', 'property', 'complexity', 'threshold']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gweQKC7ac1-",
        "colab_type": "text"
      },
      "source": [
        "We can also evaluate our model using the perplexity and coherence metrics, as we\n",
        "did before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7oYyZWwZ-X2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_coherence_model_lda_mallet = gensim.models. CoherenceModel (model=lda_mallet, corpus=bow_corpus,\n",
        "                                                               texts=norm_corpus_bigrams, dictionary=dictionary,\n",
        "                                                               coherence='c_v')\n",
        "\n",
        "avg_coherence_cv = cv_coherence_model_lda_mallet.get_coherence()\n",
        "\n",
        "umass_coherence_model_lda_mallet = gensim.models. CoherenceModel (model=lda_mallet, corpus=bow_corpus,\n",
        "                                                                   texts=norm_corpus_bigrams, dictionary=dictionary,\n",
        "                                                                  coherence='u_mass') \n",
        "\n",
        "avg_coherence_umass = umass_coherence_model_lda_mallet.get_coherence()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO9-exGmZ-WF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "274c9d44-30c7-4166-e65c-6500d1723b34"
      },
      "source": [
        "# from STDOUT: <500> LL/token: -8.53533\n",
        "perplexity = -8.53533\n",
        "\n",
        "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
        "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
        "print('Model Perplexity:', perplexity)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg. Coherence Score (Cv): 0.5143469304857831\n",
            "Avg. Coherence Score (UMass): -1.038940764502137\n",
            "Model Perplexity: -8.53533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klTqCABhbdzK",
        "colab_type": "text"
      },
      "source": [
        "You can clearly see that the model from MALLET is much better based on these\n",
        "metrics as compared to the default LDA model from Gensim. Can we find the optimal number of topics that maximizes the coherence? This is a tough problem, but we can try doing it iteratively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm-R0skIZ-TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3YtnuMlZ-Pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5KUjERPZ-Nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGVn8R-KZ-I0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6--dZELtZ-Fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vauK-jBsZ-Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}