{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for classification\n",
    "\n",
    "Previously, you evaluated the performance of your k-NN classifier based on its accuracy. However, accuracy is not always an informative metric. In this exercise, you will dive more deeply into evaluating the performance of binary classifiers by computing a confusion matrix and generating a classification report.\n",
    "\n",
    "You may have noticed that the classification report consisted of three rows, and an additional support column. The support gives the number of samples of the true response that lie in that class. The precision, recall, and f1-score columns, then, gave the respective metrics for that particular class.\n",
    "\n",
    "Here, you'll work with the PIMA Indians dataset obtained from the UCI Machine Learning Repository. The goal is to predict whether or not a given female patient will contract diabetes based on features such as BMI, age, and number of pregnancies. Therefore, it is a binary classification problem. A target value of 0 indicates that the patient does not have diabetes, while a value of 1 indicates that the patient does have diabetes.\n",
    "\n",
    "Your job is to train a k-NN classifier to the data and evaluate its performance by generating a confusion matrix and classification report.\n",
    "\n",
    "- Import classification_report and confusion_matrix from sklearn.metrics.\n",
    "- Create training and testing sets with 40% of the data used for testing. Use a random state of 42.\n",
    "- Instantiate a k-NN classifier with 6 neighbors, fit it to the training data, and predict the labels of the test set.\n",
    "- Compute and print the confusion matrix and classification report using the confusion_matrix() and classification_report() functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  diastolic   triceps     insulin   bmi    dpf  age  \\\n",
       "0            6      148         72  35.00000  155.548223  33.6  0.627   50   \n",
       "1            1       85         66  29.00000  155.548223  26.6  0.351   31   \n",
       "2            8      183         64  29.15342  155.548223  23.3  0.672   32   \n",
       "3            1       89         66  23.00000   94.000000  28.1  0.167   21   \n",
       "4            0      137         40  35.00000  168.000000  43.1  2.288   33   \n",
       "\n",
       "   diabetes  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Data/pima.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('diabetes', axis=1)\n",
    "y = df.diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176  30]\n",
      " [ 52  50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81       206\n",
      "           1       0.62      0.49      0.55       102\n",
      "\n",
      "    accuracy                           0.73       308\n",
      "   macro avg       0.70      0.67      0.68       308\n",
      "weighted avg       0.72      0.73      0.72       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Instantiate a k-NN classifier: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a logistic regression model\n",
    "\n",
    "Scikit-learn makes it very easy to try different models, since the Train-Test-Split/Instantiate/Fit/Predict paradigm applies to all classifiers and regressors - which are known in scikit-learn as 'estimators'. You'll see this now for yourself as you train a logistic regression model on exactly the same data as in the previous exercise. Will it outperform k-NN?\n",
    "\n",
    "- Import:\n",
    "    - LogisticRegression from sklearn.linear_model.\n",
    "    - confusion_matrix and classification_report from sklearn.metrics.\n",
    "- Create training and test sets with 40% (or 0.4) of the data used for testing. Use a random state of 42. This has been done for you.\n",
    "- Instantiate a LogisticRegression classifier called logreg.\n",
    "- Fit the classifier to the training data and predict the labels of the test set.\n",
    "- Compute and print the confusion matrix and classification report. compare it to k-NN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[168  38]\n",
      " [ 36  66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       206\n",
      "           1       0.63      0.65      0.64       102\n",
      "\n",
      "    accuracy                           0.76       308\n",
      "   macro avg       0.73      0.73      0.73       308\n",
      "weighted avg       0.76      0.76      0.76       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Create the classifier: logreg\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting an ROC curve\n",
    "\n",
    "Classification reports and confusion matrices are great methods to quantitatively evaluate model performance, while ROC curves provide a way to visually evaluate models. Most classifiers in scikit-learn have a `.predict_proba()` method which returns the probability of a given sample being in a particular class. Having built a logistic regression model, you'll now evaluate its performance by plotting an ROC curve. In doing so, you'll make use of the `.predict_proba()` method and become familiar with its functionality.\n",
    "\n",
    "Here, you'll continue working with the PIMA Indians diabetes dataset.\n",
    "\n",
    "- Import roc_curve from sklearn.metrics.\n",
    "- Using the logreg classifier, which has been fit to the training data, compute the predicted probabilities of the labels of the test set X_test. Save the result as y_pred_prob.\n",
    "- Use the roc_curve() function with y_test and y_pred_prob and unpack the result into the variables fpr, tpr, and thresholds.\n",
    "- Plot the ROC curve with fpr on the x-axis and tpr on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-recall Curve\n",
    "\n",
    "When looking at your ROC curve, you may have noticed that the y-axis (True positive rate) is also known as recall. Indeed, in addition to the ROC curve, there are other ways to visually evaluate model performance. One such way is the precision-recall curve, which is generated by plotting the precision and recall for different thresholds. As a reminder, precision and recall are defined as:\n",
    "\n",
    "- `Precision = TP / (TP + FP)`\n",
    "- `Recall = TP / (TP + FN)`\n",
    "\n",
    "- True negatives do not appear at all in the definitions of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# calculate model precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "# plot the model precision-recall curve\n",
    "plt.plot(recall, precision, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here, the class is positive (1) if the individual has diabetes:\n",
    "\n",
    "* A recall of 1 corresponds to a classifier with a low threshold in which all females who contract diabetes were correctly classified as such, at the expense of many misclassifications of those who did not have diabetes.\n",
    "- Precision is undefined for a classifier which makes no positive predictions, that is, classifies everyone as not having diabetes.\n",
    "- When the threshold is very close to 1, precision is also 1, because the classifier is absolutely certain about its predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC computation\n",
    "\n",
    "Say you have a binary classifier that in fact is just randomly making guesses. It would be correct approximately 50% of the time, and the resulting ROC curve would be a diagonal line in which the True Positive Rate and False Positive Rate are always equal. The Area under this ROC curve would be 0.5. This is one way in which the AUC, is an informative metric to evaluate a model. If the AUC is greater than 0.5, the model is better than random guessing. Always a good sign!\n",
    "\n",
    "In this exercise, you'll calculate AUC scores using the `roc_auc_score()` function from sklearn.metrics as well as by performing cross-validation on the diabetes dataset.\n",
    "\n",
    "- Import roc_auc_score from sklearn.metrics and cross_val_score from sklearn.model_selection.\n",
    "- Using the logreg classifier, which has been fit to the training data, compute the predicted probabilities of the labels of the test set X_test. Save the result as y_pred_prob.\n",
    "- Compute the AUC score using the `roc_auc_score()` function, the test set labels y_test, and the predicted probabilities y_pred_prob.\n",
    "- Compute the AUC scores by performing 5-fold cross-validation. Use the `cross_val_score()` function and specify the scoring parameter to be 'roc_auc'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.82609937178755\n",
      "AUC scores computed using 5-fold cross-validation: [0.81888889 0.80537037 0.82481481 0.87       0.8454717 ]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute and print AUC score\n",
    "print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\n",
    "\n",
    "# Compute cross-validated AUC scores: cv_auc\n",
    "# Compute the AUC scores by performing 5-fold cross-validation\n",
    "cv_auc = cross_val_score(logreg, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Print list of AUC scores\n",
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with GridSearchCV\n",
    "\n",
    "You will now practice to tune the n_neighbors parameter of the KNeighborsClassifier() using GridSearchCVthis yourself, by using logistic regression on the diabetes dataset.\n",
    "\n",
    "Like the alpha parameter of lasso and ridge regularization that you saw earlier, logistic regression also has a regularization parameter: C\n",
    "\n",
    "\"C\" controls the inverse of the regularization strength, and this is what you will tune in this exercise. A large C can lead to an overfit model, while a small C\n",
    "C  can lead to an underfit model. The hyperparameter space for C has been setup for you. Your job is to use GridSearchCV and logistic regression to find the optimal C\n",
    "in this hyperparameter space. The feature array is available as X and target variable array is available as y.\n",
    "\n",
    "You may be wondering why you aren't asked to split the data into training and test sets. Good observation! Here, we want you to focus on the process of setting up the hyperparameter grid and performing grid-search cross-validation. In practice, you will indeed want to hold out a portion of your data for evaluation purposes. \n",
    "\n",
    "- Import LogisticRegression from sklearn.linear_model and GridSearchCV from sklearn.model_selection.\n",
    "- Setup the hyperparameter grid by using c_space as the grid of values to tune C over.\n",
    "- Instantiate a logistic regression classifier called logreg.\n",
    "- Use GridSearchCV with 5-fold cross-validation to tune C: Inside `GridSearchCV()`, specify the classifier, parameter grid, and number of folds to use.\n",
    "- Use the `.fit()` method on the GridSearchCV object to fit it to the data X and y.\n",
    "- Print the best parameter and best score obtained from GridSearchCV by accessing the best_params_ and best_score_ attributes of logreg_cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 0.006105402296585327}\n",
      "Best score is 0.7734827264239028\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=240)\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "# Use GridSearchCV with 5-fold cross-validation to tune C\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(X, y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with RandomizedSearchCV\n",
    "\n",
    "GridSearchCV can be computationally expensive, especially if you are searching over a large hyperparameter space and dealing with multiple hyperparameters. A solution to this is to use RandomizedSearchCV, in which not all hyperparameter values are tried out. Instead, a fixed number of hyperparameter settings is sampled from specified probability distributions. You'll practice using RandomizedSearchCV in this exercise and see how this works.\n",
    "\n",
    "Here, you'll also be introduced to a new model: the Decision Tree. Don't worry about the specifics of how this model works. Just like k-NN, linear regression, and logistic regression, decision trees in scikit-learn have .fit() and .predict() methods that you can use in exactly the same way as before. Decision trees have many parameters that can be tuned, such as max_features, max_depth, and min_samples_leaf: This makes it an ideal use case for RandomizedSearchCV.\n",
    "\n",
    "Your goal is to use RandomizedSearchCV to find the optimal hyperparameters.\n",
    "\n",
    "- Import DecisionTreeClassifier from sklearn.tree and RandomizedSearchCV from sklearn.model_selection.\n",
    "- Specify the parameters and distributions to sample from. This has been done for you.\n",
    "- Instantiate a DecisionTreeClassifier.\n",
    "- Use RandomizedSearchCV with 5-fold cross-validation to tune the hyperparameters:\n",
    "- Inside `RandomizedSearchCV()`, specify the classifier, parameter distribution, and number of folds to use.\n",
    "- Use the .fit() method on the RandomizedSearchCV object to fit it to the data X and y.\n",
    "- Print the best parameter and best score obtained from RandomizedSearchCV by accessing the best_params_ and best_score_ attributes of tree_cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 8, 'min_samples_leaf': 8}\n",
      "Best score is 0.7344028520499108\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X, y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-out set in practice I: Classification\n",
    "\n",
    "You will now practice evaluating a model with tuned hyperparameters on a hold-out set. In addition to C, logistic regression has a 'penalty' hyperparameter which specifies whether to use 'l1' or 'l2' regularization. Your job in this exercise is to create a hold-out set, tune the 'C' and 'penalty' hyperparameters of a logistic regression classifier using GridSearchCV on the training set, and then evaluate its performance against the hold-out set.\n",
    "\n",
    "- Create the hyperparameter grid:\n",
    "    - Use the array c_space as the grid of values for 'C'.\n",
    "    - For 'penalty', specify a list consisting of 'l1' and 'l2'.\n",
    "- Instantiate a logistic regression classifier.\n",
    "- Create training and test sets. Use a test_size of 0.4 and random_state of 42. In practice, the test set here will function as the hold-out set.\n",
    "- Tune the hyperparameters on the training set using GridSearchCV with 5-folds. This involves first instantiating the GridSearchCV object with the correct parameters and then fitting it to the training data.\n",
    "- Print the best parameter and best score obtained from GridSearchCV by accessing the best_params_ and best_score_ attributes of logreg_cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 0.4393970560760795, 'penalty': 'l1'}\n",
      "Tuned Logistic Regression Accuracy: 0.7673913043478262\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=240)\n",
    "\n",
    "# Create training and test sets. Use a test_size of 0.4 and random_state of 42. #  In practice, the test set here will function as the hold-out set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "# Tune the hyperparameters on the training set using GridSearchCV with 5-folds. \n",
    "#  This involves first instantiating the GridSearchCV object \n",
    "#  with the correct parameters and then fitting it to the training data.\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-out set in practice II: Regression\n",
    "\n",
    "Remember lasso and ridge regression? Lasso used the L1 penalty to regularize, while ridge used the L2 penalty. There is another type of regularized regression known as the elastic net. In elastic net regularization, the penalty term is a linear combination of the L1 and L2 penalties:\n",
    "\n",
    "`a L1 + b L2`\n",
    "\n",
    "In scikit-learn, this term is represented by the 'l1_ratio' parameter: An 'l1_ratio' of 1 corresponds to an L1 penalty, and anything lower is a combination of L1 and L2.\n",
    "\n",
    "In this exercise, you will GridSearchCV to tune the 'l1_ratio' of an elastic net model trained on the Gapminder data. As in the previous exercise, use a hold-out set to evaluate your model's performance.\n",
    "\n",
    "- Import the following modules:\n",
    "    - ElasticNet from sklearn.linear_model.\n",
    "    - mean_squared_error from sklearn.metrics.\n",
    "    - GridSearchCV and train_test_split from sklearn.model_selection.\n",
    "- Create training and test sets, with 40% of the data used for the test set. Use a random state of 42.\n",
    "- Specify the hyperparameter grid for 'l1_ratio' using l1_space as the grid of values to search over.\n",
    "- Instantiate the ElasticNet regressor.\n",
    "- Use GridSearchCV with 5-fold cross-validation to tune 'l1_ratio' on the training data X_train and y_train. This involves first instantiating the GridSearchCV object with the correct parameters and then fitting it to the training data.\n",
    "- Predict on the test set and compute the R2 and mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.583095315358587, tolerance: 0.008436684782608696\n",
      "  positive)\n",
      "C:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.88582236681172, tolerance: 0.008285869565217392\n",
      "  positive)\n",
      "C:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.243853366779486, tolerance: 0.00867391304347826\n",
      "  positive)\n",
      "C:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.717344346820212, tolerance: 0.008520652173913044\n",
      "  positive)\n",
      "C:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.326082714918424, tolerance: 0.00849320652173913\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned ElasticNet l1 ratio: {'l1_ratio': 0.034482758620689655}\n",
      "Tuned ElasticNet R squared: 0.25110015989224854\n",
      "Tuned ElasticNet MSE: 0.1658783462677525\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "l1_space = np.linspace(0, 1, 30)\n",
    "param_grid = {'l1_ratio' : l1_space}\n",
    "\n",
    "# Instantiate the ElasticNet regressor: elastic_net\n",
    "elastic_net = ElasticNet(max_iter=2000)\n",
    "\n",
    "# Setup the GridSearchCV object: gm_cv\n",
    "gm_cv = GridSearchCV(elastic_net, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "gm_cv.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and compute metrics\n",
    "y_pred = gm_cv.predict(X_test)\n",
    "r2 = gm_cv.score(X_test, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\n",
    "print(\"Tuned ElasticNet R squared: {}\".format(r2))\n",
    "print(\"Tuned ElasticNet MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source : Datacamp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
